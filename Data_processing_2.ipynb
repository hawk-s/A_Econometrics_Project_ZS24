{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade    1   2   3   4   5   6   7   8   9   10\n",
      "Date                                           \n",
      "2016-09   0   0   0   1   0   0   0   2   3   0\n",
      "2016-10   0   0   0   1   0   1   0   8   2   0\n",
      "2016-11   0   0   0   0   0   0   1   4   0   0\n",
      "2016-12   0   0   0   0   0   1   0   3   1   1\n",
      "2017-01   0   0   0   0   0   0   1   1   4   1\n",
      "...      ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
      "2022-10   0   0   1   1   2   2   5   6   1   0\n",
      "2022-11   0   0   0   0   4   2   3   3   0   0\n",
      "2023-01   0   1   1   1   3   6   4   3   5   0\n",
      "2023-03   0   1   1   2   3   7   4   4   3   0\n",
      "2023-04   0   0   2   1   3   4   5   4   5   1\n",
      "\n",
      "[74 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('output_datasets/Blastoise___Holo_1999_Base_Set.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "#group the data by month and grade and count the number of each grade per month\n",
    "monthly_grade_count = df.groupby([df['Date'].dt.to_period('M'), 'Grade']).size().unstack(fill_value=0)\n",
    "\n",
    "print(monthly_grade_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of months with at least one observation per grade:\n",
      "Grade\n",
      "1      8\n",
      "2     14\n",
      "3     23\n",
      "4     34\n",
      "5     39\n",
      "6     57\n",
      "7     62\n",
      "8     67\n",
      "9     71\n",
      "10    52\n",
      "dtype: int64\n",
      "\n",
      "Total number of months in the dataset: 74\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('output_datasets/Blastoise___Holo_1999_Base_Set.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group the data by month and grade and count the number of each grade per month\n",
    "monthly_grade_count = df.groupby([df['Date'].dt.to_period('M'), 'Grade']).size().unstack(fill_value=0)\n",
    "\n",
    "# Specify the grades you are interested in\n",
    "interested_grades = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # Example grades, modify as needed\n",
    "\n",
    "# Count the number of months with at least one observation for each of the interested grades\n",
    "months_with_observations = (monthly_grade_count[interested_grades] > 0).sum(axis=0)\n",
    "\n",
    "# Count the total number of unique months in the dataset\n",
    "total_months = df['Date'].dt.to_period('M').nunique()\n",
    "\n",
    "#print(monthly_grade_count)\n",
    "print(\"\\nNumber of months with at least one observation per grade:\")\n",
    "print(months_with_observations)\n",
    "\n",
    "print(\"\\nTotal number of months in the dataset:\", total_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of months with at least one observation per grade:\n",
      "Grade\n",
      "1     28\n",
      "2     19\n",
      "3     29\n",
      "4     41\n",
      "5     52\n",
      "6     57\n",
      "7     60\n",
      "8     64\n",
      "9     61\n",
      "10    46\n",
      "dtype: int64\n",
      "\n",
      "Total number of months in the dataset: 64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('output_datasets/Charizard___Holo_1999_Base_Set.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group the data by month and grade and count the number of each grade per month\n",
    "monthly_grade_count = df.groupby([df['Date'].dt.to_period('M'), 'Grade']).size().unstack(fill_value=0)\n",
    "\n",
    "# Specify the grades you are interested in\n",
    "interested_grades = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # Example grades, modify as needed\n",
    "\n",
    "# Count the number of months with at least one observation for each of the interested grades\n",
    "months_with_observations = (monthly_grade_count[interested_grades] > 0).sum(axis=0)\n",
    "\n",
    "# Count the total number of unique months in the dataset\n",
    "total_months = df['Date'].dt.to_period('M').nunique()\n",
    "\n",
    "#print(monthly_grade_count)\n",
    "print(\"\\nNumber of months with at least one observation per grade:\")\n",
    "print(months_with_observations)\n",
    "\n",
    "print(\"\\nTotal number of months in the dataset:\", total_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of months with at least one observation per grade:\n",
      "Grade\n",
      "3      2\n",
      "4      3\n",
      "5      3\n",
      "6     16\n",
      "7     37\n",
      "8     59\n",
      "9     67\n",
      "10    36\n",
      "dtype: int64\n",
      "\n",
      "Total number of months in the dataset: 67\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('output_datasets/Charizard___Holo_2016_Evolutions.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group the data by month and grade and count the number of each grade per month\n",
    "monthly_grade_count = df.groupby([df['Date'].dt.to_period('M'), 'Grade']).size().unstack(fill_value=0)\n",
    "\n",
    "# Find the grades actually present in the DataFrame\n",
    "actual_grades = [grade for grade in range(1, 11) if grade in monthly_grade_count.columns]\n",
    "\n",
    "# Count the number of months with at least one observation for each of the actual grades\n",
    "months_with_observations = (monthly_grade_count[actual_grades] > 0).sum(axis=0)\n",
    "\n",
    "# Count the total number of unique months in the dataset\n",
    "total_months = df['Date'].dt.to_period('M').nunique()\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nNumber of months with at least one observation per grade:\")\n",
    "print(months_with_observations)\n",
    "print(\"\\nTotal number of months in the dataset:\", total_months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of months with at least one observation per grade:\n",
      "Grade\n",
      "3      1\n",
      "4      1\n",
      "5      7\n",
      "6     12\n",
      "7     23\n",
      "8     55\n",
      "9     71\n",
      "10    59\n",
      "dtype: int64\n",
      "\n",
      "Total number of months in the dataset: 71\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('output_datasets/Charizard_Reverse_Foil_2016_Evolutions.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group the data by month and grade and count the number of each grade per month\n",
    "monthly_grade_count = df.groupby([df['Date'].dt.to_period('M'), 'Grade']).size().unstack(fill_value=0)\n",
    "\n",
    "# Find the grades actually present in the DataFrame\n",
    "actual_grades = [grade for grade in range(1, 11) if grade in monthly_grade_count.columns]\n",
    "\n",
    "# Count the number of months with at least one observation for each of the actual grades\n",
    "months_with_observations = (monthly_grade_count[actual_grades] > 0).sum(axis=0)\n",
    "\n",
    "# Count the total number of unique months in the dataset\n",
    "total_months = df['Date'].dt.to_period('M').nunique()\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nNumber of months with at least one observation per grade:\")\n",
    "print(months_with_observations)\n",
    "print(\"\\nTotal number of months in the dataset:\", total_months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of months with at least one observation per grade:\n",
      "Grade\n",
      "4      1\n",
      "5      4\n",
      "6      8\n",
      "7     13\n",
      "8     42\n",
      "9     68\n",
      "10    73\n",
      "dtype: int64\n",
      "\n",
      "Total number of months in the dataset: 73\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('output_datasets/Full_Art_M_Charizard_EX___Holo_2016_Evolutions.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group the data by month and grade and count the number of each grade per month\n",
    "monthly_grade_count = df.groupby([df['Date'].dt.to_period('M'), 'Grade']).size().unstack(fill_value=0)\n",
    "\n",
    "# Find the grades actually present in the DataFrame\n",
    "actual_grades = [grade for grade in range(1, 11) if grade in monthly_grade_count.columns]\n",
    "\n",
    "# Count the number of months with at least one observation for each of the actual grades\n",
    "months_with_observations = (monthly_grade_count[actual_grades] > 0).sum(axis=0)\n",
    "\n",
    "# Count the total number of unique months in the dataset\n",
    "total_months = df['Date'].dt.to_period('M').nunique()\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nNumber of months with at least one observation per grade:\")\n",
    "print(months_with_observations)\n",
    "print(\"\\nTotal number of months in the dataset:\", total_months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of months with at least one observation per grade:\n",
      "Grade\n",
      "1      5\n",
      "2     12\n",
      "3     23\n",
      "4     29\n",
      "5     53\n",
      "6     56\n",
      "7     67\n",
      "8     66\n",
      "9     71\n",
      "10    46\n",
      "dtype: int64\n",
      "\n",
      "Total number of months in the dataset: 73\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('output_datasets/Machamp_1st_Edition__Holo_1999_Base_Set.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group the data by month and grade and count the number of each grade per month\n",
    "monthly_grade_count = df.groupby([df['Date'].dt.to_period('M'), 'Grade']).size().unstack(fill_value=0)\n",
    "\n",
    "# Find the grades actually present in the DataFrame\n",
    "actual_grades = [grade for grade in range(1, 11) if grade in monthly_grade_count.columns]\n",
    "\n",
    "# Count the number of months with at least one observation for each of the actual grades\n",
    "months_with_observations = (monthly_grade_count[actual_grades] > 0).sum(axis=0)\n",
    "\n",
    "# Count the total number of unique months in the dataset\n",
    "total_months = df['Date'].dt.to_period('M').nunique()\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nNumber of months with at least one observation per grade:\")\n",
    "print(months_with_observations)\n",
    "print(\"\\nTotal number of months in the dataset:\", total_months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of months with at least one observation per grade:\n",
      "Grade\n",
      "1     10\n",
      "2     10\n",
      "3     21\n",
      "4     26\n",
      "5     35\n",
      "6     48\n",
      "7     53\n",
      "8     63\n",
      "9     70\n",
      "10    53\n",
      "dtype: int64\n",
      "\n",
      "Total number of months in the dataset: 75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('output_datasets/Venusaur___Holo_1999_Base_Set.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group the data by month and grade and count the number of each grade per month\n",
    "monthly_grade_count = df.groupby([df['Date'].dt.to_period('M'), 'Grade']).size().unstack(fill_value=0)\n",
    "\n",
    "# Find the grades actually present in the DataFrame\n",
    "actual_grades = [grade for grade in range(1, 11) if grade in monthly_grade_count.columns]\n",
    "\n",
    "# Count the number of months with at least one observation for each of the actual grades\n",
    "months_with_observations = (monthly_grade_count[actual_grades] > 0).sum(axis=0)\n",
    "\n",
    "# Count the total number of unique months in the dataset\n",
    "total_months = df['Date'].dt.to_period('M').nunique()\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nNumber of months with at least one observation per grade:\")\n",
    "print(months_with_observations)\n",
    "print(\"\\nTotal number of months in the dataset:\", total_months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grades to include in the analysis: [6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the proportion of months with observations for each grade\n",
    "proportion_of_months = months_with_observations / total_months\n",
    "\n",
    "# Set the threshold (e.g., 50%)\n",
    "threshold = 0.5\n",
    "\n",
    "# Determine which grades meet or exceed the threshold\n",
    "grades_to_include = proportion_of_months[proportion_of_months >= threshold].index.tolist()\n",
    "\n",
    "print(\"Grades to include in the analysis:\", grades_to_include)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_datasets(threshold, aggregation_method='mean', input_folder='output_datasets', output_folder='final_cards_datasets'):\n",
    "    \"\"\"\n",
    "    Processes datasets of Pokemon card grades, creating monthly averages and forward filling based on a threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - threshold (float): The minimum proportion of months with observations required to keep a grade.\n",
    "    - aggregation_method (str): Method to aggregate price data ('mean', 'median', or 'mode').\n",
    "    - input_folder (str): Folder containing the input datasets.\n",
    "    - output_folder (str): Folder where processed datasets will be saved.\n",
    "\n",
    "    The function processes each dataset by:\n",
    "    1. Filtering grades based on the threshold of monthly observations.\n",
    "    2. Calculating monthly averages for prices of the remaining grades.\n",
    "    3. Forward filling missing monthly data.\n",
    "    4. Saving the processed datasets in the specified output folder.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Define aggregation function\n",
    "    if aggregation_method == 'mean':\n",
    "        agg_func = 'mean'\n",
    "    elif aggregation_method == 'median':\n",
    "        agg_func = 'median'\n",
    "    elif aggregation_method == 'mode':\n",
    "        agg_func = lambda x: x.mode().iloc[0] if not x.empty else x\n",
    "    else:\n",
    "        raise ValueError(\"Invalid aggregation method. Choose 'mean', 'median', or 'mode'.\")\n",
    "\n",
    "    # Loop through files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Read the dataset\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "            # Group by month and grade, and count observations\n",
    "            monthly_grade_count = df.groupby([df['Date'].dt.to_period('M'), 'Grade']).size().unstack(fill_value=0)\n",
    "\n",
    "            # Total number of unique months\n",
    "            total_months = df['Date'].dt.to_period('M').nunique()\n",
    "\n",
    "            # Calculate the proportion of months with observations for each grade\n",
    "            proportion_of_months = (monthly_grade_count > 0).sum() / total_months\n",
    "\n",
    "            # Filter grades based on the threshold\n",
    "            grades_to_keep = proportion_of_months[proportion_of_months >= threshold].index\n",
    "\n",
    "            # Keep only the grades that meet the threshold\n",
    "            filtered_df = df[df['Grade'].isin(grades_to_keep)]\n",
    "\n",
    "            # Aggregate price data by month and grade\n",
    "            monthly_data = filtered_df.groupby([filtered_df['Date'].dt.to_period('M'), 'Grade']).agg({'Price': agg_func}).reset_index()\n",
    "\n",
    "            # Forward fill missing observations\n",
    "            monthly_data = monthly_data.set_index('Date').groupby('Grade').resample('M').ffill().reset_index(level=0, drop=True).reset_index()\n",
    "\n",
    "            # Save the processed dataset\n",
    "            monthly_data.to_csv(os.path.join(output_folder, filename), index=False)\n",
    "\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "# Example usage\n",
    "process_datasets(threshold=0.5, aggregation_method='mean')  # Set your threshold and aggregation method here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved: merged_datasets\\merged_Blastoise___Holo_1999_Base_Set.csv\n",
      "Merged dataset saved: merged_datasets\\merged_Charizard_Reverse_Foil_2016_Evolutions.csv\n",
      "Merged dataset saved: merged_datasets\\merged_Charizard___Holo_1999_Base_Set.csv\n",
      "Merged dataset saved: merged_datasets\\merged_Charizard___Holo_2016_Evolutions.csv\n",
      "Merged dataset saved: merged_datasets\\merged_Full_Art_Charizard_GX_2019_Hidden_Fates.csv\n",
      "Merged dataset saved: merged_datasets\\merged_Full_Art_Charizard_Vmax_Portuguese__Holo_2020_Darkness_Ablaze.csv\n",
      "Merged dataset saved: merged_datasets\\merged_Full_Art_Charizard_Vmax_Secret__Holo_2020_Champions_Path.csv\n",
      "Merged dataset saved: merged_datasets\\merged_Full_Art_M_Charizard_EX___Holo_2016_Evolutions.csv\n",
      "Merged dataset saved: merged_datasets\\merged_Machamp_1st_Edition__Holo_1999_Base_Set.csv\n",
      "Merged dataset saved: merged_datasets\\merged_Venusaur___Holo_1999_Base_Set.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_pokemon_with_sp500(pokemon_folder, sp500_file, output_folder):\n",
    "    \"\"\"\n",
    "    Merge each Pokémon card dataset with the S&P 500 dataset based on the date.\n",
    "\n",
    "    Parameters:\n",
    "    pokemon_folder (str): Path to the folder containing Pokémon card datasets.\n",
    "    sp500_file (str): Path to the S&P 500 dataset file.\n",
    "    output_folder (str): Path to the folder where merged datasets will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None: Saves the merged datasets in the specified output folder.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Load the S&P 500 data\n",
    "    sp500_data = pd.read_csv(sp500_file)\n",
    "    sp500_data['Date'] = pd.to_datetime(sp500_data['Date'])\n",
    "\n",
    "    # Iterate over files in the Pokémon folder\n",
    "    for filename in os.listdir(pokemon_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(pokemon_folder, filename)\n",
    "            pokemon_data = pd.read_csv(file_path)\n",
    "            pokemon_data['Date'] = pd.to_datetime(pokemon_data['Date'])\n",
    "\n",
    "            # Reshape Pokémon data to wide format\n",
    "            pokemon_pivot = pokemon_data.pivot(index='Date', columns='Grade', values='Price')\n",
    "\n",
    "            # Merge with S&P 500 data\n",
    "            merged_data = pd.merge(pokemon_pivot, sp500_data, on='Date', how='inner')\n",
    "\n",
    "            # Forward fill missing values\n",
    "            merged_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "            # Save the merged dataset\n",
    "            merged_output_path = os.path.join(output_folder, 'merged_' + filename)\n",
    "            merged_data.to_csv(merged_output_path, index=False)\n",
    "\n",
    "            print(f'Merged dataset saved: {merged_output_path}')\n",
    "\n",
    "# Example usage\n",
    "pokemon_folder = 'final_cards_datasets'\n",
    "sp500_file = '^GSPC_output_main.csv'\n",
    "output_folder = 'merged_datasets'\n",
    "merge_pokemon_with_sp500(pokemon_folder, sp500_file, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_and_save_datasets(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Processes each dataset in the specified input folder by applying backward fill to missing values. \n",
    "    The processed datasets are then saved in the specified output folder.\n",
    "\n",
    "    :param input_folder: The folder containing the original datasets.\n",
    "    :param output_folder: The folder where processed datasets will be saved.\n",
    "    \"\"\"\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Process each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            data = pd.read_csv(file_path)\n",
    "\n",
    "            # Apply backward fill for missing values\n",
    "            data.bfill(inplace=True)\n",
    "\n",
    "            # Save the processed dataset to the output folder\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            data.to_csv(output_path, index=False)\n",
    "\n",
    "            print(f\"Processed and saved {filename}\")\n",
    "\n",
    "# Example usage\n",
    "process_and_save_datasets('merged_datasets', 'merged_datasets_final')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
